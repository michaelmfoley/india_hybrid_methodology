{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c0799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Geometry is in a geographic CRS.*\")\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57620538",
   "metadata": {},
   "source": [
    "# Load in hybrid boundary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe006e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hybrid(shp_path, hybrid_stats_path):\n",
    "    \"\"\"\n",
    "    Merges hybrid boundary shapefile with hybrid statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    shp_path (str): Path to the hybrid boundary shapefile.\n",
    "    hybrid_stats_path (str): Path to the hybrid statistics CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    gpd.GeoDataFrame: Merged GeoDataFrame containing hybrid boundaries and statistics.\n",
    "    \"\"\"\n",
    "    hybrid = gpd.read_file(shp_path)\n",
    "    hybrid_stats = pd.read_csv(hybrid_stats_path)\n",
    "    \n",
    "    stats = hybrid_stats[['Admin 2', 'Year', 'Area Harvested: ha', 'Yield: MT/ha', 'Quantity Produced: MT', 'Source crop']]\n",
    "    stats.columns = [\"name_state\", \"year\", \"area_harvested\", \"yield\", \"production\", \"ag_hy_crop\"]\n",
    "    \n",
    "    merged_hybrid = stats.merge(hybrid, how='left')\n",
    "    merged_hybrid = gpd.GeoDataFrame(merged_hybrid, geometry='geometry')\n",
    "    \n",
    "    return hybrid, merged_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = \"../shapefiles/2016_2023_hybrid_boundary_071925.shp\" \n",
    "hybrid_stats_path = \"../../data/temporally_harmonized_crop_data_072425.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ac7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid, merged_hybrid = merge_hybrid(shp_path, hybrid_stats_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abfc19",
   "metadata": {},
   "source": [
    "# Load in ICRISAT product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the 1966 boundaries with names matched to ICRISAT data\n",
    "icri_path = \"../shapefiles/icrisat_apportioned/icrisat_boundary_match.shp\"\n",
    "icri = gpd.read_file(icri_path)\n",
    "\n",
    "icri_apportioned_path = '../shapefiles/icrisat_apportioned/ICRISAT-District Level Data_Apportioned.csv'\n",
    "icri_data = pd.read_csv(icri_apportioned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3de14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "icri.head(10).to_csv(\"icri_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b6ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hybrid.crs != icri.crs:\n",
    "    icri = icri.to_crs(hybrid.crs)\n",
    "\n",
    "colname1 = \"name\"\n",
    "colname2 = \"Dist_Name\"\n",
    "\n",
    "hybrid['name'] = hybrid[colname1]\n",
    "icri['name'] = icri[colname2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43abc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the ICRISAT apportioned data\n",
    "icri = icri.rename(columns={'Name_12': 'Dist Name', 'NAME_1' : 'State Name'})\n",
    "icri.loc[icri['State Name']== \"Uttaranchal\", \"State Name\"] = \"Uttar Pradesh\"\n",
    "merged_icri = gpd.GeoDataFrame(icri.merge(icri_data, how=\"left\", on=['Dist Name', 'State Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a749d",
   "metadata": {},
   "source": [
    "# Constrained optimization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6c8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_all_crops_all_years(merged_hybrid_data, trained_optimizer, years=None):\n",
    "    \"\"\"\n",
    "    Apply trained weights to ALL crops in your data for all years (2016-2022)\n",
    "    Uses weights trained on Wheat/Soyabean/Barley and applies to all crops\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_hybrid_data : pd.DataFrame\n",
    "        Your full dataset with all crops and years\n",
    "    trained_optimizer : FastSpatialOptimizer\n",
    "        Your trained optimizer (trained on 3 crops)\n",
    "    years : list, optional\n",
    "        Years to transform (defaults to 2016-2022)\n",
    "    \"\"\"\n",
    "    \n",
    "    if years is None:\n",
    "        years = [2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    \n",
    "    # Get all available crops from your data\n",
    "    all_crops = sorted(merged_hybrid_data['ag_hy_crop'].unique())\n",
    "    \n",
    "    # Filter to crops that have ICRISAT mappings\n",
    "    crops_with_mappings = []\n",
    "    crops_without_mappings = []\n",
    "    \n",
    "    for crop in all_crops:\n",
    "        if crop.upper() in trained_optimizer.crop_mapping:\n",
    "            crops_with_mappings.append(crop)\n",
    "        else:\n",
    "            crops_without_mappings.append(crop)\n",
    "    \n",
    "    print(\"=== TRANSFORMING ALL CROPS TO ICRISAT FORMAT ===\")\n",
    "    print(f\"Using weights trained on: Wheat, Soyabean, Barley\")\n",
    "    print(f\"Applying to {len(crops_with_mappings)} crops with ICRISAT mappings\")\n",
    "    print(f\"Years: {years}\")\n",
    "    \n",
    "    if crops_without_mappings:\n",
    "        print(f\"\\n⚠️  {len(crops_without_mappings)} crops without ICRISAT mappings (will be skipped):\")\n",
    "        for crop in crops_without_mappings[:10]:  # Show first 10\n",
    "            print(f\"    {crop}\")\n",
    "        if len(crops_without_mappings) > 10:\n",
    "            print(f\"    ... and {len(crops_without_mappings)-10} more\")\n",
    "    \n",
    "    print(f\"\\n✅ Crops to be transformed:\")\n",
    "    for crop in crops_with_mappings:\n",
    "        icrisat_crop = trained_optimizer.crop_mapping.get(crop.upper(), crop.upper())\n",
    "        print(f\"  {crop} -> {icrisat_crop}\")\n",
    "    \n",
    "    # Create reverse mapping from target indices to district names\n",
    "    target_idx_to_name = {idx: name for name, idx in trained_optimizer.target_name_to_idx.items()}\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"\\n=== PROCESSING YEARS ===\")\n",
    "    for year in years:\n",
    "        print(f\"\\nProcessing {year}...\")\n",
    "        \n",
    "        year_totals = {'original_area': 0, 'original_prod': 0, 'transformed_area': 0, 'transformed_prod': 0}\n",
    "        \n",
    "        for crop in crops_with_mappings:\n",
    "            # Prepare source data for this crop and year\n",
    "            try:\n",
    "                crop_data = trained_optimizer.prepare_crop_data_vectors_only(merged_hybrid_data, crop, year)\n",
    "                \n",
    "                # Transform using trained weights (from Wheat/Soyabean/Barley)\n",
    "                transformed_area = trained_optimizer.weight_matrix_area @ crop_data['source_area']\n",
    "                transformed_production = trained_optimizer.weight_matrix_production @ crop_data['source_production']\n",
    "                \n",
    "                # Get ICRISAT crop name\n",
    "                icrisat_crop = trained_optimizer.crop_mapping.get(crop.upper(), crop.upper())\n",
    "                \n",
    "                # Track totals for conservation check\n",
    "                orig_area = crop_data['source_area'].sum()\n",
    "                orig_prod = crop_data['source_production'].sum()\n",
    "                trans_area = transformed_area.sum()\n",
    "                trans_prod = transformed_production.sum()\n",
    "                \n",
    "                year_totals['original_area'] += orig_area\n",
    "                year_totals['original_prod'] += orig_prod\n",
    "                year_totals['transformed_area'] += trans_area\n",
    "                year_totals['transformed_prod'] += trans_prod\n",
    "                \n",
    "                # Create results for this crop\n",
    "                for target_idx in range(trained_optimizer.n_target):\n",
    "                    district_name = target_idx_to_name[target_idx]\n",
    "                    \n",
    "                    area_val = transformed_area[target_idx]\n",
    "                    prod_val = transformed_production[target_idx]\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'district_name': district_name,\n",
    "                        'year': year,\n",
    "                        'crop': crop,\n",
    "                        'icrisat_crop': icrisat_crop,\n",
    "                        'area_ha': area_val,\n",
    "                        'production_tons': prod_val,\n",
    "                        'yield_kg_per_ha': prod_val / area_val if area_val > 0 else 0\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️  Error processing {crop}: {e}\")\n",
    "        \n",
    "        # Print year-level conservation summary\n",
    "        area_conservation = abs(year_totals['transformed_area'] - year_totals['original_area']) / year_totals['original_area'] * 100 if year_totals['original_area'] > 0 else 0\n",
    "        prod_conservation = abs(year_totals['transformed_prod'] - year_totals['original_prod']) / year_totals['original_prod'] * 100 if year_totals['original_prod'] > 0 else 0\n",
    "        \n",
    "        print(f\"  Year {year} totals: Area conservation error: {area_conservation:.2f}%, Prod conservation error: {prod_conservation:.2f}%\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(f\"\\n✅ ALL CROPS TRANSFORMATION COMPLETE!\")\n",
    "    print(f\"Output shape: {result_df.shape}\")\n",
    "    print(f\"Years: {sorted(result_df['year'].unique())}\")\n",
    "    print(f\"Crops transformed: {len(result_df['crop'].unique())}\")\n",
    "    print(f\"Districts: {len(result_df['district_name'].unique())}\")\n",
    "    \n",
    "    # Summary by crop\n",
    "    print(f\"\\nCrop summary:\")\n",
    "    crop_summary = result_df.groupby('crop').agg({\n",
    "        'area_ha': 'sum',\n",
    "        'production_tons': 'sum'\n",
    "    }).round(0)\n",
    "    \n",
    "    for crop in crop_summary.index[:10]:  # Show top 10 crops by area\n",
    "        area = crop_summary.loc[crop, 'area_ha']\n",
    "        prod = crop_summary.loc[crop, 'production_tons']\n",
    "        print(f\"  {crop}: {area:,.0f} ha, {prod:,.0f} tons\")\n",
    "    \n",
    "    if len(crop_summary) > 10:\n",
    "        print(f\"  ... and {len(crop_summary)-10} more crops\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_full_icrisat_format(transformed_long_df):\n",
    "    \"\"\"\n",
    "    Convert the long format (all crops) to ICRISAT wide format\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    transformed_long_df : pd.DataFrame\n",
    "        Output from transform_all_crops_all_years()\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== CREATING FULL ICRISAT FORMAT ===\")\n",
    "    \n",
    "    # Get unique combinations\n",
    "    years = sorted(transformed_long_df['year'].unique())\n",
    "    districts = sorted(transformed_long_df['district_name'].unique())\n",
    "    crops = sorted(transformed_long_df['icrisat_crop'].unique())\n",
    "    \n",
    "    print(f\"Years: {len(years)}\")\n",
    "    print(f\"Districts: {len(districts)}\")  \n",
    "    print(f\"Crops: {len(crops)}\")\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"Processing {year}...\")\n",
    "        \n",
    "        for district in districts:\n",
    "            # Start row with district info\n",
    "            row = {\n",
    "                'name': district,\n",
    "                'Year': year\n",
    "            }\n",
    "            \n",
    "            # Get data for this district-year\n",
    "            district_year_data = transformed_long_df[\n",
    "                (transformed_long_df['district_name'] == district) & \n",
    "                (transformed_long_df['year'] == year)\n",
    "            ]\n",
    "            \n",
    "            # Add each crop's data as columns\n",
    "            for _, crop_row in district_year_data.iterrows():\n",
    "                icrisat_crop = crop_row['icrisat_crop']\n",
    "                \n",
    "                # Create column names in ICRISAT format\n",
    "                area_col = f'{icrisat_crop} AREA (1000 ha)'\n",
    "                prod_col = f'{icrisat_crop} PRODUCTION (1000 tons)'\n",
    "                yield_col = f'{icrisat_crop} YIELD (Kg per ha)'\n",
    "                \n",
    "                # Convert back to ICRISAT units (divide by 1000)\n",
    "                row[area_col] = crop_row['area_ha'] / 1000\n",
    "                row[prod_col] = crop_row['production_tons'] / 1000\n",
    "                row[yield_col] = crop_row['yield_kg_per_ha']\n",
    "            \n",
    "            all_rows.append(row)\n",
    "    \n",
    "    result_df = pd.DataFrame(all_rows)\n",
    "    \n",
    "    print(f\"✅ FULL ICRISAT FORMAT CREATED!\")\n",
    "    print(f\"Shape: {result_df.shape}\")\n",
    "    print(f\"Columns: {len(result_df.columns)} (name, Year + {len(result_df.columns)-2} crop columns)\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c9892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete FastSpatialOptimizer class for spatial weight optimization\n",
      "\n",
      "Main functions:\n",
      "1. run_fast_optimization() - Train weights on 3 crops\n",
      "2. transform_all_crops_all_years() - Apply to all crops\n",
      "\n",
      "Usage:\n",
      "# Train\n",
      "results = run_fast_optimization(merged_hybrid, merged_icri, hybrid_bounds, icri_bounds, crop_key)\n",
      "# Transform all\n",
      "all_data = transform_all_crops_all_years(merged_hybrid, results['optimizer'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class FastSpatialOptimizer:\n",
    "    \"\"\"\n",
    "    Fast spatial weight optimizer using iterative proportional fitting (IPF)\n",
    "    Much faster and more stable than constrained optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.intersection_mask = None\n",
    "        self.initial_weights = None\n",
    "        self.weight_matrix_area = None\n",
    "        self.weight_matrix_production = None\n",
    "        self.crop_mapping = None\n",
    "        \n",
    "    def load_crop_mapping(self, crop_key_df):\n",
    "        \"\"\"Load crop mapping from your cropkey.csv\"\"\"\n",
    "        self.crop_mapping = dict(zip(\n",
    "            crop_key_df['crop'].str.upper(), \n",
    "            crop_key_df['icrisat_crop'].str.upper()\n",
    "        ))\n",
    "        print(f\"Loaded {len(self.crop_mapping)} crop mappings\")\n",
    "        \n",
    "    def compute_intersections(self, source_boundaries, target_boundaries):\n",
    "        \"\"\"Compute spatial intersections - same as before but faster\"\"\"\n",
    "        print(\"Computing spatial intersections...\")\n",
    "        \n",
    "        # Ensure same CRS\n",
    "        if source_boundaries.crs != target_boundaries.crs:\n",
    "            target_boundaries = target_boundaries.to_crs(source_boundaries.crs)\n",
    "        \n",
    "        n_target = len(target_boundaries)\n",
    "        n_source = len(source_boundaries)\n",
    "        \n",
    "        print(f\"Source districts: {n_source}\")\n",
    "        print(f\"Target districts: {n_target}\")\n",
    "        \n",
    "        # Initialize sparse intersection matrix\n",
    "        intersection_weights = {}  # (i,j): weight\n",
    "        \n",
    "        # Create mappings\n",
    "        source_name_to_idx = {row['name_state']: idx for idx, row in source_boundaries.iterrows()}\n",
    "        target_name_to_idx = {row['name']: idx for idx, row in target_boundaries.iterrows()}\n",
    "        \n",
    "        # Store the mappings\n",
    "        self.source_name_to_idx = source_name_to_idx\n",
    "        self.target_name_to_idx = target_name_to_idx\n",
    "        self.n_source = n_source\n",
    "        self.n_target = n_target\n",
    "        \n",
    "        # Compute intersections - only store non-zero weights\n",
    "        intersection_count = 0\n",
    "        for i, target_row in target_boundaries.iterrows():\n",
    "            target_geom = target_row.geometry\n",
    "            target_idx = target_name_to_idx[target_row['name']]\n",
    "            \n",
    "            for j, source_row in source_boundaries.iterrows():\n",
    "                source_geom = source_row.geometry\n",
    "                source_idx = source_name_to_idx[source_row['name_state']]\n",
    "                \n",
    "                if target_geom.intersects(source_geom):\n",
    "                    intersect_area = target_geom.intersection(source_geom).area\n",
    "                    source_area = source_geom.area\n",
    "                    if intersect_area > 0:\n",
    "                        weight = intersect_area / source_area\n",
    "                        intersection_weights[(target_idx, source_idx)] = weight\n",
    "                        intersection_count += 1\n",
    "        \n",
    "        self.intersection_weights = intersection_weights\n",
    "        print(f\"Found {intersection_count} spatial intersections\")\n",
    "        return intersection_weights\n",
    "    \n",
    "    def prepare_crop_data(self, source_data, target_data, crop_name, year):\n",
    "        \"\"\"Prepare data for one crop and year - same as before\"\"\"\n",
    "        \n",
    "        # Get ICRISAT crop name\n",
    "        if self.crop_mapping is None:\n",
    "            raise ValueError(\"Must load crop mapping first\")\n",
    "            \n",
    "        icrisat_crop = self.crop_mapping.get(crop_name.upper(), crop_name.upper())\n",
    "        \n",
    "        # Filter source data\n",
    "        source_subset = source_data[\n",
    "            (source_data['year'] == year) & \n",
    "            (source_data['ag_hy_crop'] == crop_name)\n",
    "        ].copy()\n",
    "        \n",
    "        # Filter target data  \n",
    "        target_subset = target_data[target_data['Year'] == year].copy()\n",
    "        \n",
    "        # Create vectors\n",
    "        source_area = np.zeros(self.n_source)\n",
    "        source_production = np.zeros(self.n_source)\n",
    "        target_area = np.zeros(self.n_target)\n",
    "        target_production = np.zeros(self.n_target)\n",
    "        \n",
    "        # Fill source vectors\n",
    "        for _, row in source_subset.iterrows():\n",
    "            if row['name_state'] in self.source_name_to_idx:\n",
    "                idx = self.source_name_to_idx[row['name_state']]\n",
    "                source_area[idx] = row['area_harvested'] if pd.notna(row['area_harvested']) else 0\n",
    "                source_production[idx] = row['production'] if pd.notna(row['production']) else 0\n",
    "        \n",
    "        # ICRISAT column names\n",
    "        area_col = f'{icrisat_crop} AREA (1000 ha)'\n",
    "        prod_col = f'{icrisat_crop} PRODUCTION (1000 tons)'\n",
    "        \n",
    "        # Fill target vectors and convert units\n",
    "        for _, row in target_subset.iterrows():\n",
    "            if row['name'] in self.target_name_to_idx:\n",
    "                idx = self.target_name_to_idx[row['name']]\n",
    "                if area_col in target_subset.columns and pd.notna(row[area_col]):\n",
    "                    target_area[idx] = row[area_col] * 1000  # Convert to ha\n",
    "                if prod_col in target_subset.columns and pd.notna(row[prod_col]):\n",
    "                    target_production[idx] = row[prod_col] * 1000  # Convert to tons\n",
    "        \n",
    "        print(f\"  {crop_name} -> {icrisat_crop}\")\n",
    "        print(f\"    Source area: {source_area.sum():.0f}, target area: {target_area.sum():.0f}\")\n",
    "        print(f\"    Source prod: {source_production.sum():.0f}, target prod: {target_production.sum():.0f}\")\n",
    "        \n",
    "        return {\n",
    "            'source_area': source_area,\n",
    "            'source_production': source_production,\n",
    "            'target_area': target_area, \n",
    "            'target_production': target_production,\n",
    "            'icrisat_crop': icrisat_crop\n",
    "        }\n",
    "    \n",
    "    def prepare_crop_data_vectors_only(self, source_data, crop_name, year):\n",
    "        \"\"\"\n",
    "        Helper function to prepare just the source vectors for transformation\n",
    "        (doesn't need target data since we're just transforming)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter source data\n",
    "        source_subset = source_data[\n",
    "            (source_data['year'] == year) & \n",
    "            (source_data['ag_hy_crop'] == crop_name)\n",
    "        ].copy()\n",
    "        \n",
    "        # Create source vectors\n",
    "        source_area = np.zeros(self.n_source)\n",
    "        source_production = np.zeros(self.n_source)\n",
    "        \n",
    "        # Fill source vectors\n",
    "        for _, row in source_subset.iterrows():\n",
    "            if row['name_state'] in self.source_name_to_idx:\n",
    "                idx = self.source_name_to_idx[row['name_state']]\n",
    "                source_area[idx] = row['area_harvested'] if pd.notna(row['area_harvested']) else 0\n",
    "                source_production[idx] = row['production'] if pd.notna(row['production']) else 0\n",
    "        \n",
    "        return {\n",
    "            'source_area': source_area,\n",
    "            'source_production': source_production\n",
    "        }\n",
    "    \n",
    "    def optimize_weights_ipf(self, crop_data_dict, data_type='area', max_iterations=50):\n",
    "        \"\"\"\n",
    "        Optimize weights using Iterative Proportional Fitting (IPF)\n",
    "        Much faster and more stable than constrained optimization\n",
    "        \"\"\"\n",
    "        \n",
    "        crops = list(crop_data_dict.keys())\n",
    "        n_crops = len(crops)\n",
    "        \n",
    "        print(f\"Optimizing {data_type} weights using IPF...\")\n",
    "        print(f\"  Crops: {crops}\")\n",
    "        \n",
    "        # Prepare data matrices\n",
    "        source_matrix = np.zeros((self.n_source, n_crops))\n",
    "        target_matrix = np.zeros((self.n_target, n_crops))\n",
    "        \n",
    "        for i, crop in enumerate(crops):\n",
    "            if data_type == 'area':\n",
    "                source_matrix[:, i] = crop_data_dict[crop]['source_area']\n",
    "                target_matrix[:, i] = crop_data_dict[crop]['target_area']\n",
    "            else:\n",
    "                source_matrix[:, i] = crop_data_dict[crop]['source_production']\n",
    "                target_matrix[:, i] = crop_data_dict[crop]['target_production']\n",
    "        \n",
    "        # Check for valid crops\n",
    "        valid_crops = []\n",
    "        valid_cols = []\n",
    "        for i, crop in enumerate(crops):\n",
    "            if source_matrix[:, i].sum() > 0 and target_matrix[:, i].sum() > 0:\n",
    "                valid_crops.append(crop)\n",
    "                valid_cols.append(i)\n",
    "        \n",
    "        if len(valid_crops) == 0:\n",
    "            print(\"❌ No valid crops\")\n",
    "            return np.zeros((self.n_target, self.n_source))\n",
    "        \n",
    "        print(f\"  Valid crops: {valid_crops}\")\n",
    "        \n",
    "        # Use only valid crops\n",
    "        source_matrix = source_matrix[:, valid_cols]\n",
    "        target_matrix = target_matrix[:, valid_cols]\n",
    "        \n",
    "        # Initialize weight matrix with area proportions\n",
    "        W = np.zeros((self.n_target, self.n_source))\n",
    "        for (i, j), weight in self.intersection_weights.items():\n",
    "            W[i, j] = weight\n",
    "        \n",
    "        # Normalize so each source column sums to 1\n",
    "        col_sums = W.sum(axis=0)\n",
    "        for j in range(self.n_source):\n",
    "            if col_sums[j] > 0:\n",
    "                W[:, j] = W[:, j] / col_sums[j]\n",
    "        \n",
    "        print(f\"  Starting IPF with {len(self.intersection_weights)} non-zero weights...\")\n",
    "        \n",
    "        # IPF iterations\n",
    "        for iteration in range(max_iterations):\n",
    "            W_old = W.copy()\n",
    "            \n",
    "            # For each crop, adjust weights to match target totals\n",
    "            for crop_idx in range(len(valid_crops)):\n",
    "                source_vec = source_matrix[:, crop_idx]\n",
    "                target_vec = target_matrix[:, crop_idx]\n",
    "                \n",
    "                # Skip if no data\n",
    "                source_total = source_vec.sum()\n",
    "                target_total = target_vec.sum()\n",
    "                if source_total == 0 or target_total == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Current prediction\n",
    "                predicted = W @ source_vec\n",
    "                predicted_total = predicted.sum()\n",
    "                \n",
    "                # Adjust weights proportionally to match target total\n",
    "                if predicted_total > 0:\n",
    "                    adjustment_factor = target_total / predicted_total\n",
    "                    \n",
    "                    # Apply adjustment only to non-zero weights\n",
    "                    for (i, j) in self.intersection_weights.keys():\n",
    "                        if source_vec[j] > 0:  # Only adjust if source has data\n",
    "                            W[i, j] *= adjustment_factor\n",
    "            \n",
    "            # Check convergence\n",
    "            weight_change = np.max(np.abs(W - W_old))\n",
    "            if weight_change < 1e-6:\n",
    "                print(f\"  ✅ IPF converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "            \n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                print(f\"    Iteration {iteration + 1}, max weight change: {weight_change:.6f}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"  ⚠️  IPF reached max iterations ({max_iterations})\")\n",
    "        \n",
    "        # Store results\n",
    "        if data_type == 'area':\n",
    "            self.weight_matrix_area = W\n",
    "        else:\n",
    "            self.weight_matrix_production = W\n",
    "        \n",
    "        # Calculate and print final results\n",
    "        predicted_matrix = W @ source_matrix\n",
    "        \n",
    "        print(f\"  Final Results:\")\n",
    "        total_rmse = 0\n",
    "        for i, crop in enumerate(valid_crops):\n",
    "            predicted = predicted_matrix[:, i]\n",
    "            actual = target_matrix[:, i]\n",
    "            \n",
    "            rmse = np.sqrt(np.mean((predicted - actual)**2))\n",
    "            total_rmse += rmse\n",
    "            \n",
    "            source_total = source_matrix[:, i].sum()\n",
    "            target_total = actual.sum()\n",
    "            predicted_total = predicted.sum()\n",
    "            conservation_error = abs(predicted_total - target_total)\n",
    "            conservation_pct = conservation_error / target_total * 100 if target_total > 0 else 0\n",
    "            \n",
    "            print(f\"    {crop}: RMSE={rmse:.0f}, Conservation error={conservation_error:.0f} ({conservation_pct:.2f}%)\")\n",
    "            print(f\"      Source: {source_total:.0f}, Target: {target_total:.0f}, Predicted: {predicted_total:.0f}\")\n",
    "        \n",
    "        print(f\"  Average RMSE: {total_rmse/len(valid_crops):.0f}\")\n",
    "        return W\n",
    "    \n",
    "    def validate_on_test_year(self, source_data, target_data, crops, test_year):\n",
    "        \"\"\"Test the trained weights on a different year\"\"\"\n",
    "        \n",
    "        print(f\"\\n=== TESTING ON YEAR {test_year} ===\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        test_crop_data = {}\n",
    "        for crop in crops:\n",
    "            test_crop_data[crop] = self.prepare_crop_data(source_data, target_data, crop, test_year)\n",
    "        \n",
    "        # Test area weights\n",
    "        if self.weight_matrix_area is not None:\n",
    "            print(\"\\nTesting AREA weights:\")\n",
    "            self._test_weights(test_crop_data, 'area')\n",
    "        \n",
    "        # Test production weights  \n",
    "        if self.weight_matrix_production is not None:\n",
    "            print(\"\\nTesting PRODUCTION weights:\")\n",
    "            self._test_weights(test_crop_data, 'production')\n",
    "    \n",
    "    def _test_weights(self, crop_data_dict, data_type):\n",
    "        \"\"\"Helper function to test weights\"\"\"\n",
    "        \n",
    "        crops = list(crop_data_dict.keys())\n",
    "        \n",
    "        # Get weight matrix\n",
    "        W = self.weight_matrix_area if data_type == 'area' else self.weight_matrix_production\n",
    "        \n",
    "        # Prepare test data\n",
    "        source_matrix = np.zeros((self.n_source, len(crops)))\n",
    "        target_matrix = np.zeros((self.n_target, len(crops)))\n",
    "        \n",
    "        for i, crop in enumerate(crops):\n",
    "            if data_type == 'area':\n",
    "                source_matrix[:, i] = crop_data_dict[crop]['source_area']\n",
    "                target_matrix[:, i] = crop_data_dict[crop]['target_area']\n",
    "            else:\n",
    "                source_matrix[:, i] = crop_data_dict[crop]['source_production']\n",
    "                target_matrix[:, i] = crop_data_dict[crop]['target_production']\n",
    "        \n",
    "        # Predict\n",
    "        predicted_matrix = W @ source_matrix\n",
    "        \n",
    "        # Calculate metrics\n",
    "        print(f\"  Test Results:\")\n",
    "        total_rmse = 0\n",
    "        valid_crops = 0\n",
    "        \n",
    "        for i, crop in enumerate(crops):\n",
    "            predicted = predicted_matrix[:, i]\n",
    "            actual = target_matrix[:, i]\n",
    "            \n",
    "            if actual.sum() > 0:\n",
    "                rmse = np.sqrt(np.mean((predicted - actual)**2))\n",
    "                total_rmse += rmse\n",
    "                valid_crops += 1\n",
    "                conservation_error = abs(predicted.sum() - actual.sum())\n",
    "                conservation_pct = conservation_error / actual.sum() * 100\n",
    "                \n",
    "                print(f\"    {crop}: RMSE={rmse:.0f}, Conservation error={conservation_error:.0f} ({conservation_pct:.2f}%)\")\n",
    "        \n",
    "        if valid_crops > 0:\n",
    "            print(f\"  Average Test RMSE: {total_rmse/valid_crops:.0f}\")\n",
    "\n",
    "def run_fast_optimization(merged_hybrid_data, merged_icri_data, hybrid_boundaries, icri_boundaries, crop_key_df):\n",
    "    \"\"\"\n",
    "    Fast workflow using IPF for Wheat, Soyabean, and Barley\n",
    "    \"\"\"\n",
    "    \n",
    "    crops = ['Wheat', 'Soyabean', 'Barley']\n",
    "    \n",
    "    print(\"=== FAST SPATIAL WEIGHT OPTIMIZATION ===\")\n",
    "    print(f\"Target crops: {crops}\")\n",
    "    print(\"Using Iterative Proportional Fitting (IPF) - much faster!\")\n",
    "    \n",
    "    # Initialize\n",
    "    optimizer = FastSpatialOptimizer()\n",
    "    optimizer.load_crop_mapping(crop_key_df)\n",
    "    \n",
    "    # Compute intersections\n",
    "    optimizer.compute_intersections(hybrid_boundaries, icri_boundaries)\n",
    "    \n",
    "    # Prepare training data (2016)\n",
    "    print(f\"\\n=== PREPARING TRAINING DATA (2016) ===\")\n",
    "    train_crop_data = {}\n",
    "    for crop in crops:\n",
    "        train_crop_data[crop] = optimizer.prepare_crop_data(merged_hybrid_data, merged_icri_data, crop, 2016)\n",
    "    \n",
    "    # Train using IPF - much faster!\n",
    "    print(f\"\\n=== TRAINING AREA WEIGHTS ===\")\n",
    "    area_weights = optimizer.optimize_weights_ipf(train_crop_data, 'area')\n",
    "    \n",
    "    print(f\"\\n=== TRAINING PRODUCTION WEIGHTS ===\") \n",
    "    prod_weights = optimizer.optimize_weights_ipf(train_crop_data, 'production')\n",
    "    \n",
    "    # Test on 2017\n",
    "    optimizer.validate_on_test_year(merged_hybrid_data, merged_icri_data, crops, 2017)\n",
    "    \n",
    "    print(f\"\\n=== OPTIMIZATION COMPLETE ===\")\n",
    "    \n",
    "    return {\n",
    "        'optimizer': optimizer,\n",
    "        'area_weights': area_weights,\n",
    "        'production_weights': prod_weights,\n",
    "        'crops': crops\n",
    "    }\n",
    "\n",
    "def transform_all_crops_all_years(merged_hybrid_data, trained_optimizer, years=None):\n",
    "    \"\"\"\n",
    "    Apply trained weights to ALL crops in your data for all years (2016-2022)\n",
    "    Uses weights trained on Wheat/Soyabean/Barley and applies to all crops\n",
    "    \"\"\"\n",
    "    \n",
    "    if years is None:\n",
    "        years = [2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    \n",
    "    # Get all available crops from your data\n",
    "    all_crops = sorted(merged_hybrid_data['ag_hy_crop'].unique())\n",
    "    \n",
    "    # Filter to crops that have ICRISAT mappings\n",
    "    crops_with_mappings = []\n",
    "    crops_without_mappings = []\n",
    "    \n",
    "    for crop in all_crops:\n",
    "        if crop.upper() in trained_optimizer.crop_mapping:\n",
    "            crops_with_mappings.append(crop)\n",
    "        else:\n",
    "            crops_without_mappings.append(crop)\n",
    "    \n",
    "    print(\"=== TRANSFORMING ALL CROPS TO ICRISAT FORMAT ===\")\n",
    "    print(f\"Using weights trained on: Wheat, Soyabean, Barley\")\n",
    "    print(f\"Applying to {len(crops_with_mappings)} crops with ICRISAT mappings\")\n",
    "    print(f\"Years: {years}\")\n",
    "    \n",
    "    if crops_without_mappings:\n",
    "        print(f\"\\n⚠️  {len(crops_without_mappings)} crops without ICRISAT mappings (will be skipped):\")\n",
    "        for crop in crops_without_mappings[:10]:  # Show first 10\n",
    "            print(f\"    {crop}\")\n",
    "        if len(crops_without_mappings) > 10:\n",
    "            print(f\"    ... and {len(crops_without_mappings)-10} more\")\n",
    "    \n",
    "    print(f\"\\n✅ Crops to be transformed:\")\n",
    "    for crop in crops_with_mappings:\n",
    "        icrisat_crop = trained_optimizer.crop_mapping.get(crop.upper(), crop.upper())\n",
    "        print(f\"  {crop} -> {icrisat_crop}\")\n",
    "    \n",
    "    # Create reverse mapping from target indices to district names\n",
    "    target_idx_to_name = {idx: name for name, idx in trained_optimizer.target_name_to_idx.items()}\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"\\n=== PROCESSING YEARS ===\")\n",
    "    for year in years:\n",
    "        print(f\"\\nProcessing {year}...\")\n",
    "        \n",
    "        year_totals = {'original_area': 0, 'original_prod': 0, 'transformed_area': 0, 'transformed_prod': 0}\n",
    "        \n",
    "        for crop in crops_with_mappings:\n",
    "            # Prepare source data for this crop and year\n",
    "            try:\n",
    "                crop_data = trained_optimizer.prepare_crop_data_vectors_only(merged_hybrid_data, crop, year)\n",
    "                \n",
    "                # Transform using trained weights (from Wheat/Soyabean/Barley)\n",
    "                transformed_area = trained_optimizer.weight_matrix_area @ crop_data['source_area']\n",
    "                transformed_production = trained_optimizer.weight_matrix_production @ crop_data['source_production']\n",
    "                \n",
    "                # Get ICRISAT crop name\n",
    "                icrisat_crop = trained_optimizer.crop_mapping.get(crop.upper(), crop.upper())\n",
    "                \n",
    "                # Track totals for conservation check\n",
    "                orig_area = crop_data['source_area'].sum()\n",
    "                orig_prod = crop_data['source_production'].sum()\n",
    "                trans_area = transformed_area.sum()\n",
    "                trans_prod = transformed_production.sum()\n",
    "                \n",
    "                year_totals['original_area'] += orig_area\n",
    "                year_totals['original_prod'] += orig_prod\n",
    "                year_totals['transformed_area'] += trans_area\n",
    "                year_totals['transformed_prod'] += trans_prod\n",
    "                \n",
    "                # Create results for this crop\n",
    "                for target_idx in range(trained_optimizer.n_target):\n",
    "                    district_name = target_idx_to_name[target_idx]\n",
    "                    \n",
    "                    area_val = transformed_area[target_idx]\n",
    "                    prod_val = transformed_production[target_idx]\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'district_name': district_name,\n",
    "                        'year': year,\n",
    "                        'crop': crop,\n",
    "                        'icrisat_crop': icrisat_crop,\n",
    "                        'area_ha': area_val,\n",
    "                        'production_tons': prod_val,\n",
    "                        'yield_kg_per_ha': prod_val / area_val if area_val > 0 else 0\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️  Error processing {crop}: {e}\")\n",
    "        \n",
    "        # Print year-level conservation summary\n",
    "        area_conservation = abs(year_totals['transformed_area'] - year_totals['original_area']) / year_totals['original_area'] * 100 if year_totals['original_area'] > 0 else 0\n",
    "        prod_conservation = abs(year_totals['transformed_prod'] - year_totals['original_prod']) / year_totals['original_prod'] * 100 if year_totals['original_prod'] > 0 else 0\n",
    "        \n",
    "        print(f\"  Year {year} totals: Area conservation error: {area_conservation:.2f}%, Prod conservation error: {prod_conservation:.2f}%\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(f\"\\n✅ ALL CROPS TRANSFORMATION COMPLETE!\")\n",
    "    print(f\"Output shape: {result_df.shape}\")\n",
    "    print(f\"Years: {sorted(result_df['year'].unique())}\")\n",
    "    print(f\"Crops transformed: {len(result_df['crop'].unique())}\")\n",
    "    print(f\"Districts: {len(result_df['district_name'].unique())}\")\n",
    "    \n",
    "    # Summary by crop\n",
    "    print(f\"\\nCrop summary:\")\n",
    "    crop_summary = result_df.groupby('crop').agg({\n",
    "        'area_ha': 'sum',\n",
    "        'production_tons': 'sum'\n",
    "    }).round(0)\n",
    "    \n",
    "    for crop in crop_summary.index[:10]:  # Show top 10 crops by area\n",
    "        area = crop_summary.loc[crop, 'area_ha']\n",
    "        prod = crop_summary.loc[crop, 'production_tons']\n",
    "        print(f\"  {crop}: {area:,.0f} ha, {prod:,.0f} tons\")\n",
    "    \n",
    "    if len(crop_summary) > 10:\n",
    "        print(f\"  ... and {len(crop_summary)-10} more crops\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Complete FastSpatialOptimizer class for spatial weight optimization\")\n",
    "    print()\n",
    "    print(\"Main functions:\")\n",
    "    print(\"1. run_fast_optimization() - Train weights on 3 crops\")\n",
    "    print(\"2. transform_all_crops_all_years() - Apply to all crops\")\n",
    "    print()\n",
    "    print(\"Usage:\")\n",
    "    print(\"# Train\")\n",
    "    print(\"results = run_fast_optimization(merged_hybrid, merged_icri, hybrid_bounds, icri_bounds, crop_key)\")\n",
    "    print(\"# Transform all\")\n",
    "    print(\"all_data = transform_all_crops_all_years(merged_hybrid, results['optimizer'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2a9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_key = pd.read_csv('../../data/cropkey.csv')  # Load your cropkey.csv with crop mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b206d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAST SPATIAL WEIGHT OPTIMIZATION ===\n",
      "Target crops: ['Wheat', 'Soyabean', 'Barley']\n",
      "Using Iterative Proportional Fitting (IPF) - much faster!\n",
      "Loaded 48 crop mappings\n",
      "Computing spatial intersections...\n",
      "Source districts: 676\n",
      "Target districts: 310\n",
      "Found 2614 spatial intersections\n",
      "\n",
      "=== PREPARING TRAINING DATA (2016) ===\n",
      "  Wheat -> WHEAT\n",
      "    Source area: 31763623, target area: 31486790\n",
      "    Source prod: 113458953, target prod: 112962820\n",
      "  Soyabean -> SOYABEAN\n",
      "    Source area: 11173537, target area: 11134020\n",
      "    Source prod: 13182453, target prod: 13133130\n",
      "  Barley -> BARLEY\n",
      "    Source area: 654021, target area: 645530\n",
      "    Source prod: 1931442, target prod: 1923680\n",
      "\n",
      "=== TRAINING AREA WEIGHTS ===\n",
      "Optimizing area weights using IPF...\n",
      "  Crops: ['Wheat', 'Soyabean', 'Barley']\n",
      "  Valid crops: ['Wheat', 'Soyabean', 'Barley']\n",
      "  Starting IPF with 2614 non-zero weights...\n",
      "    Iteration 10, max weight change: 0.000702\n",
      "    Iteration 20, max weight change: 0.000034\n",
      "    Iteration 30, max weight change: 0.000002\n",
      "  ✅ IPF converged after 32 iterations\n",
      "  Final Results:\n",
      "    Wheat: RMSE=25126, Conservation error=17 (0.00%)\n",
      "      Source: 31763623, Target: 31486790, Predicted: 31486773\n",
      "    Soyabean: RMSE=3462, Conservation error=2 (0.00%)\n",
      "      Source: 11173537, Target: 11134020, Predicted: 11134018\n",
      "    Barley: RMSE=2883, Conservation error=0 (0.00%)\n",
      "      Source: 654021, Target: 645530, Predicted: 645530\n",
      "  Average RMSE: 10490\n",
      "\n",
      "=== TRAINING PRODUCTION WEIGHTS ===\n",
      "Optimizing production weights using IPF...\n",
      "  Crops: ['Wheat', 'Soyabean', 'Barley']\n",
      "  Valid crops: ['Wheat', 'Soyabean', 'Barley']\n",
      "  Starting IPF with 2614 non-zero weights...\n",
      "    Iteration 10, max weight change: 0.000166\n",
      "    Iteration 20, max weight change: 0.000006\n",
      "  ✅ IPF converged after 26 iterations\n",
      "  Final Results:\n",
      "    Wheat: RMSE=111984, Conservation error=60 (0.00%)\n",
      "      Source: 113458953, Target: 112962820, Predicted: 112962760\n",
      "    Soyabean: RMSE=4737, Conservation error=2 (0.00%)\n",
      "      Source: 13182453, Target: 13133130, Predicted: 13133128\n",
      "    Barley: RMSE=10579, Conservation error=0 (0.00%)\n",
      "      Source: 1931442, Target: 1923680, Predicted: 1923680\n",
      "  Average RMSE: 42433\n",
      "\n",
      "=== TESTING ON YEAR 2017 ===\n",
      "  Wheat -> WHEAT\n",
      "    Source area: 30584306, target area: 30055810\n",
      "    Source prod: 111550283, target prod: 110418210\n",
      "  Soyabean -> SOYABEAN\n",
      "    Source area: 10324184, target area: 10284630\n",
      "    Source prod: 11111506, target prod: 11062440\n",
      "  Barley -> BARLEY\n",
      "    Source area: 633550, target area: 626790\n",
      "    Source prod: 1931027, target prod: 1922120\n",
      "\n",
      "Testing AREA weights:\n",
      "  Test Results:\n",
      "    Wheat: RMSE=25677, Conservation error=259880 (0.86%)\n",
      "    Soyabean: RMSE=3396, Conservation error=3736 (0.04%)\n",
      "    Barley: RMSE=3469, Conservation error=490 (0.08%)\n",
      "  Average Test RMSE: 10847\n",
      "\n",
      "Testing PRODUCTION weights:\n",
      "  Test Results:\n",
      "    Wheat: RMSE=113149, Conservation error=572368 (0.52%)\n",
      "    Soyabean: RMSE=4120, Conservation error=3119 (0.03%)\n",
      "    Barley: RMSE=13686, Conservation error=2241 (0.12%)\n",
      "  Average Test RMSE: 43652\n",
      "\n",
      "=== OPTIMIZATION COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "# Run the complete workflow\n",
    "results = run_fast_optimization(\n",
    "    merged_hybrid, merged_icri, hybrid, icri, crop_key\n",
    ")\n",
    "\n",
    "# Get your trained weight matrices\n",
    "area_weights = results['area_weights']        # For transforming area data\n",
    "production_weights = results['production_weights']  # For transforming production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "246d93fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSFORMING ALL CROPS TO ICRISAT FORMAT ===\n",
      "Using weights trained on: Wheat, Soyabean, Barley\n",
      "Applying to 47 crops with ICRISAT mappings\n",
      "Years: [2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
      "\n",
      "⚠️  1 crops without ICRISAT mappings (will be skipped):\n",
      "    Turmeric\n",
      "\n",
      "✅ Crops to be transformed:\n",
      "  Arecanut -> nan\n",
      "  Arhar/Tur -> PIGEONPEA\n",
      "  Bajra -> PEARL MILLET\n",
      "  Banana -> nan\n",
      "  Barley -> BARLEY\n",
      "  Black pepper -> nan\n",
      "  Cardamom -> nan\n",
      "  Cashewnut -> nan\n",
      "  Castor seed -> CASTOR\n",
      "  Coconut -> nan\n",
      "  Coriander -> nan\n",
      "  Cotton(lint) -> COTTON\n",
      "  Cowpea(Lobia) -> nan\n",
      "  Dry chillies -> nan\n",
      "  Garlic -> nan\n",
      "  Ginger -> nan\n",
      "  Groundnut -> GROUNDNUT\n",
      "  Guar seed -> nan\n",
      "  Horse-gram -> nan\n",
      "  Jowar -> SORGHUM\n",
      "  Jute -> nan\n",
      "  Khesari -> nan\n",
      "  Linseed -> nan\n",
      "  Maize -> MAIZE\n",
      "  Masoor -> nan\n",
      "  Mesta -> nan\n",
      "  Moong(Green Gram) -> nan\n",
      "  Moth -> nan\n",
      "  Niger seed -> nan\n",
      "  Onion -> ONION\n",
      "  Other Cereals -> nan\n",
      "  Peas & beans (Pulses) -> nan\n",
      "  Potato -> POTATOES\n",
      "  Ragi -> FINGER MILLET\n",
      "  Rapeseed &Mustard -> RAPESEED AND MUSTARD\n",
      "  Rice -> RICE\n",
      "  Safflower -> nan\n",
      "  Sannhamp -> nan\n",
      "  Sesamum -> SESAMUM\n",
      "  Small millets -> nan\n",
      "  Soyabean -> SOYABEAN\n",
      "  Sugarcane -> SUGARCANE\n",
      "  Sweet potato -> nan\n",
      "  Tapioca -> nan\n",
      "  Tobacco -> nan\n",
      "  Urad -> nan\n",
      "  Wheat -> WHEAT\n",
      "\n",
      "=== PROCESSING YEARS ===\n",
      "\n",
      "Processing 2016...\n",
      "  Year 2016 totals: Area conservation error: 0.85%, Prod conservation error: 0.52%\n",
      "\n",
      "Processing 2017...\n",
      "  Year 2017 totals: Area conservation error: 0.81%, Prod conservation error: 0.49%\n",
      "\n",
      "Processing 2018...\n",
      "  Year 2018 totals: Area conservation error: 0.79%, Prod conservation error: 0.48%\n",
      "\n",
      "Processing 2019...\n",
      "  Year 2019 totals: Area conservation error: 0.72%, Prod conservation error: 0.39%\n",
      "\n",
      "Processing 2020...\n",
      "  Year 2020 totals: Area conservation error: 0.55%, Prod conservation error: 0.29%\n",
      "\n",
      "Processing 2021...\n",
      "  Year 2021 totals: Area conservation error: 0.40%, Prod conservation error: 0.23%\n",
      "\n",
      "Processing 2022...\n",
      "  Year 2022 totals: Area conservation error: 0.45%, Prod conservation error: 0.25%\n",
      "\n",
      "✅ ALL CROPS TRANSFORMATION COMPLETE!\n",
      "Output shape: (101990, 7)\n",
      "Years: [np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022)]\n",
      "Crops transformed: 47\n",
      "Districts: 310\n",
      "\n",
      "Crop summary:\n",
      "  Arecanut: 4,636,047 ha, 34,683,499 tons\n",
      "  Arhar/Tur: 31,800,395 ha, 28,927,975 tons\n",
      "  Bajra: 48,930,996 ha, 69,791,403 tons\n",
      "  Banana: 2,332,143 ha, 93,633,663 tons\n",
      "  Barley: 3,933,798 ha, 12,078,689 tons\n",
      "  Black pepper: 1,684,385 ha, 825,224 tons\n",
      "  Cardamom: 354,744 ha, 130,550 tons\n",
      "  Cashewnut: 2,109,797 ha, 1,449,400 tons\n",
      "  Castor seed: 5,986,344 ha, 11,265,012 tons\n",
      "  Coconut: 13,682,598 ha, 0 tons\n",
      "  ... and 37 more crops\n"
     ]
    }
   ],
   "source": [
    "# Now apply to ALL crops:\n",
    "all_crops_data = transform_all_crops_all_years(\n",
    "    merged_hybrid,           # Your full dataset with all crops\n",
    "    results['optimizer'] # Your trained optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2e3f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing functions for crop data transformation\n",
      "\n",
      "Usage:\n",
      "1. clean_and_enhance_output(transformed_df, crop_key_df)\n",
      "2. create_clean_icrisat_format(cleaned_long_df)\n",
      "3. verify_district_alignment(cleaned_data, icrisat_boundaries)\n",
      "\n",
      "Example:\n",
      "# Clean the data\n",
      "cleaned = clean_and_enhance_output(all_crops_transformed, crop_key)\n",
      "# Create ICRISAT format\n",
      "icrisat_wide = create_clean_icrisat_format(cleaned)\n",
      "# Verify alignment\n",
      "alignment = verify_district_alignment(cleaned, icrisat_boundaries)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_and_enhance_output(transformed_df, crop_key_df):\n",
    "    \"\"\"\n",
    "    Post-processing: Keep only crops with ICRISAT mappings and add ICRISAT crop names\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    transformed_df : pd.DataFrame\n",
    "        Output from transform_all_crops_all_years() \n",
    "    crop_key_df : pd.DataFrame\n",
    "        Your crop mapping (cropkey.csv)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame: Cleaned data with only mapped crops and ICRISAT names\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== CLEANING AND ENHANCING OUTPUT ===\")\n",
    "    \n",
    "    # Create mapping dictionary\n",
    "    crop_mapping = dict(zip(\n",
    "        crop_key_df['crop'].str.strip().str.upper(), \n",
    "        crop_key_df['icrisat_crop'].str.strip().str.upper()\n",
    "    ))\n",
    "    \n",
    "    print(f\"Original data: {len(transformed_df):,} rows, {len(transformed_df['crop'].unique())} crops\")\n",
    "    \n",
    "    # Filter to only crops that have mappings\n",
    "    crops_with_mappings = set(crop_mapping.keys())\n",
    "    available_crops = set(transformed_df['crop'].str.upper())\n",
    "    \n",
    "    # Find intersection\n",
    "    valid_crops = crops_with_mappings.intersection(available_crops)\n",
    "    crops_to_keep = [crop for crop in transformed_df['crop'].unique() \n",
    "                     if crop.upper() in valid_crops]\n",
    "    \n",
    "    print(f\"Crops with ICRISAT mappings: {len(crops_to_keep)}\")\n",
    "    \n",
    "    # Filter dataframe\n",
    "    filtered_df = transformed_df[transformed_df['crop'].isin(crops_to_keep)].copy()\n",
    "    \n",
    "    # Add ICRISAT crop names as a separate column\n",
    "    filtered_df['icrisat_crop_name'] = filtered_df['crop'].str.upper().map(crop_mapping)\n",
    "    \n",
    "    # Reorder columns to put ICRISAT crop name next to original crop name\n",
    "    cols = ['district_name', 'year', 'crop', 'icrisat_crop_name', 'area_ha', 'production_tons', 'yield_kg_per_ha']\n",
    "    if 'icrisat_crop' in filtered_df.columns:\n",
    "        # Remove the old icrisat_crop column if it exists\n",
    "        filtered_df = filtered_df.drop('icrisat_crop', axis=1)\n",
    "    \n",
    "    filtered_df = filtered_df[cols]\n",
    "    \n",
    "    print(f\"Final data: {len(filtered_df):,} rows, {len(filtered_df['crop'].unique())} crops\")\n",
    "    \n",
    "    # Show crop mapping summary\n",
    "    print(f\"\\nCrop mappings applied:\")\n",
    "    crop_summary = filtered_df.groupby(['crop', 'icrisat_crop_name']).size().reset_index(name='observations')\n",
    "    for _, row in crop_summary.iterrows():\n",
    "        print(f\"  {row['crop']} -> {row['icrisat_crop_name']} ({row['observations']:,} obs)\")\n",
    "    \n",
    "    # Check for any missing mappings\n",
    "    missing_mappings = filtered_df[filtered_df['icrisat_crop_name'].isna()]\n",
    "    if len(missing_mappings) > 0:\n",
    "        print(f\"\\n⚠️  {len(missing_mappings)} rows with missing ICRISAT mappings\")\n",
    "        missing_crops = missing_mappings['crop'].unique()\n",
    "        print(f\"Missing crops: {list(missing_crops)}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def create_clean_icrisat_format(cleaned_long_df):\n",
    "    \"\"\"\n",
    "    Create ICRISAT wide format from cleaned long format data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cleaned_long_df : pd.DataFrame\n",
    "        Output from clean_and_enhance_output()\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== CREATING CLEAN ICRISAT FORMAT ===\")\n",
    "    \n",
    "    # Get unique combinations\n",
    "    years = sorted(cleaned_long_df['year'].unique())\n",
    "    districts = sorted(cleaned_long_df['district_name'].unique())\n",
    "    icrisat_crops = sorted(cleaned_long_df['icrisat_crop_name'].unique())\n",
    "    \n",
    "    print(f\"Years: {len(years)}\")\n",
    "    print(f\"Districts: {len(districts)}\")  \n",
    "    print(f\"ICRISAT crops: {len(icrisat_crops)}\")\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for year in years:\n",
    "        for district in districts:\n",
    "            # Start row with district info\n",
    "            row = {\n",
    "                'name': district,\n",
    "                'Year': year\n",
    "            }\n",
    "            \n",
    "            # Get data for this district-year\n",
    "            district_year_data = cleaned_long_df[\n",
    "                (cleaned_long_df['district_name'] == district) & \n",
    "                (cleaned_long_df['year'] == year)\n",
    "            ]\n",
    "            \n",
    "            # Add each crop's data as columns using ICRISAT names\n",
    "            for _, crop_row in district_year_data.iterrows():\n",
    "                icrisat_crop = crop_row['icrisat_crop_name']\n",
    "                \n",
    "                # Create column names in ICRISAT format\n",
    "                area_col = f'{icrisat_crop} AREA (1000 ha)'\n",
    "                prod_col = f'{icrisat_crop} PRODUCTION (1000 tons)'\n",
    "                yield_col = f'{icrisat_crop} YIELD (Kg per ha)'\n",
    "                \n",
    "                # Convert back to ICRISAT units (divide by 1000)\n",
    "                row[area_col] = crop_row['area_ha'] / 1000\n",
    "                row[prod_col] = crop_row['production_tons'] / 1000\n",
    "                row[yield_col] = crop_row['yield_kg_per_ha']\n",
    "            \n",
    "            all_rows.append(row)\n",
    "    \n",
    "    result_df = pd.DataFrame(all_rows)\n",
    "    \n",
    "    print(f\"✅ CLEAN ICRISAT FORMAT CREATED!\")\n",
    "    print(f\"Shape: {result_df.shape}\")\n",
    "    print(f\"Columns: {len(result_df.columns)} (name, Year + {len(result_df.columns)-2} crop columns)\")\n",
    "    \n",
    "    # Show sample of column names\n",
    "    crop_cols = [col for col in result_df.columns if col not in ['name', 'Year']]\n",
    "    print(f\"Sample crop columns: {crop_cols[:6]}\")\n",
    "    if len(crop_cols) > 6:\n",
    "        print(f\"... and {len(crop_cols)-6} more\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def verify_district_alignment(cleaned_data, icrisat_boundaries):\n",
    "    \"\"\"\n",
    "    Verify that district names in your transformed data match ICRISAT boundaries\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cleaned_data : pd.DataFrame\n",
    "        Output from clean_and_enhance_output()\n",
    "    icrisat_boundaries : geopandas.GeoDataFrame\n",
    "        Your ICRISAT boundaries with 'name' column\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== VERIFYING DISTRICT ALIGNMENT ===\")\n",
    "    \n",
    "    # Get district names from both\n",
    "    final_districts = set(cleaned_data['district_name'].unique())\n",
    "    icrisat_districts = set(icrisat_boundaries['name'].unique())\n",
    "    \n",
    "    print(f\"Districts in transformed data: {len(final_districts)}\")\n",
    "    print(f\"Districts in ICRISAT boundaries: {len(icrisat_districts)}\")\n",
    "    \n",
    "    # Check alignment\n",
    "    perfect_match = final_districts == icrisat_districts\n",
    "    print(f\"Perfect match: {perfect_match}\")\n",
    "    \n",
    "    if not perfect_match:\n",
    "        missing_in_boundaries = final_districts - icrisat_districts\n",
    "        missing_in_data = icrisat_districts - final_districts\n",
    "        \n",
    "        if missing_in_boundaries:\n",
    "            print(f\"\\nDistricts in data but not in boundaries: {len(missing_in_boundaries)}\")\n",
    "            for district in list(missing_in_boundaries)[:5]:\n",
    "                print(f\"  {district}\")\n",
    "            if len(missing_in_boundaries) > 5:\n",
    "                print(f\"  ... and {len(missing_in_boundaries)-5} more\")\n",
    "        \n",
    "        if missing_in_data:\n",
    "            print(f\"\\nDistricts in boundaries but not in data: {len(missing_in_data)}\")\n",
    "            for district in list(missing_in_data)[:5]:\n",
    "                print(f\"  {district}\")\n",
    "            if len(missing_in_data) > 5:\n",
    "                print(f\"  ... and {len(missing_in_data)-5} more\")\n",
    "    \n",
    "    overlap = len(final_districts.intersection(icrisat_districts))\n",
    "    overlap_pct = overlap / len(icrisat_districts) * 100\n",
    "    print(f\"\\nOverlap: {overlap}/{len(icrisat_districts)} districts ({overlap_pct:.1f}%)\")\n",
    "    \n",
    "    if overlap_pct > 95:\n",
    "        print(\"✅ Excellent alignment - ready for mapping!\")\n",
    "    elif overlap_pct > 90:\n",
    "        print(\"⚠️  Good alignment - minor mismatches\")\n",
    "    else:\n",
    "        print(\"❌ Poor alignment - check district name matching\")\n",
    "    \n",
    "    return {\n",
    "        'perfect_match': perfect_match,\n",
    "        'overlap_count': overlap,\n",
    "        'overlap_percentage': overlap_pct,\n",
    "        'missing_in_boundaries': missing_in_boundaries if not perfect_match else set(),\n",
    "        'missing_in_data': missing_in_data if not perfect_match else set()\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Post-processing functions for crop data transformation\")\n",
    "    print()\n",
    "    print(\"Usage:\")\n",
    "    print(\"1. clean_and_enhance_output(transformed_df, crop_key_df)\")\n",
    "    print(\"2. create_clean_icrisat_format(cleaned_long_df)\")\n",
    "    print(\"3. verify_district_alignment(cleaned_data, icrisat_boundaries)\")\n",
    "    print()\n",
    "    print(\"Example:\")\n",
    "    print(\"# Clean the data\")\n",
    "    print(\"cleaned = clean_and_enhance_output(all_crops_transformed, crop_key)\")\n",
    "    print(\"# Create ICRISAT format\") \n",
    "    print(\"icrisat_wide = create_clean_icrisat_format(cleaned)\")\n",
    "    print(\"# Verify alignment\")\n",
    "    print(\"alignment = verify_district_alignment(cleaned, icrisat_boundaries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d4c25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_crops_transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# After you've run transform_all_crops_all_years():\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Clean up the results (filter to mapped crops + add ICRISAT names)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m clean_and_enhance_output(\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mall_crops_transformed\u001b[49m,  \u001b[38;5;66;03m# Your raw output \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     crop_key_df            \u001b[38;5;66;03m# Your crop mapping\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Save the cleaned long format\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cleaned_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_crops_icrisat_clean_long.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_crops_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "# After you've run transform_all_crops_all_years():\n",
    "# Clean up the results (filter to mapped crops + add ICRISAT names)\n",
    "cleaned_data = clean_and_enhance_output(\n",
    "    all_crops_data,  # Your raw output \n",
    "    crop_key            # Your crop mapping\n",
    ")\n",
    "\n",
    "# Save the cleaned long format\n",
    "cleaned_data.to_csv('all_crops_icrisat_clean_long.csv', index=False)\n",
    "\n",
    "# Create clean ICRISAT wide format\n",
    "clean_icrisat_wide = create_clean_icrisat_format(cleaned_data)\n",
    "clean_icrisat_wide.to_csv('all_crops_icrisat_clean_wide.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eee9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
